{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1989,"status":"ok","timestamp":1623654877631,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"NlGYnRhPD0p4"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1623654881497,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"MrX9vXLNxfVK"},"outputs":[],"source":["base_dir = \"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1623654884288,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"45aVlUyH6t5f"},"outputs":[],"source":["import os\n","import shutil"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1875,"status":"ok","timestamp":1623654889502,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"XK4Fefynx6GN"},"outputs":[],"source":["class_labels = os.listdir(os.path.join(base_dir,\"Train\"))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":587,"status":"ok","timestamp":1623654891558,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"iVyfg0FjxZkf"},"outputs":[],"source":["def create_validation_dir():\n","\n","  cv_dir = os.path.join(base_dir,\"cv\")\n","  os.mkdir(cv_dir)\n","  train_dir = os.path.join(base_dir,\"Train\")\n","\n","  for class_label in class_labels:\n","    class_label_dir = os.path.join(cv_dir,class_label)\n","    os.mkdir(class_label_dir)\n","\n","  for class_label in class_labels:\n","    class_label_train_dir = os.path.join(train_dir,class_label)\n","    class_label_cv_dir = os.path.join(cv_dir,class_label)\n","    cv_class_images = os.listdir(class_label_train_dir)[0:int(0.2*1700)]\n","    \n","    for img in cv_class_images:\n","      src = os.path.join(class_label_train_dir,img)\n","      dst = os.path.join(class_label_cv_dir,img)\n","      shutil.move(src,dst)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1623654892817,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"Mh6EUglDF5mk"},"outputs":[],"source":["training_datagen = ImageDataGenerator()\n","testing_datagen = ImageDataGenerator()\n","cv_datagen = ImageDataGenerator()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84156,"status":"ok","timestamp":1623654978585,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"Cp7Et-e8Gkfh","outputId":"04576072-9713-4e01-a492-7a4a44197e12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 62560 images belonging to 46 classes.\n"]}],"source":["train_generator = training_datagen.flow_from_directory(\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train\",\n","                                                       target_size=(32,32),color_mode=\"grayscale\",batch_size=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JaESlpXQ5yoB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 15640 images belonging to 46 classes.\n"]}],"source":["validation_generator = cv_datagen.flow_from_directory(\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/cv\",\n","                                                      target_size=(32,32),color_mode=\"grayscale\",batch_size=15640)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17831,"status":"ok","timestamp":1623647417471,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"LicpmbkLIcMs","outputId":"5ba59b0e-fa08-4505-b386-541e78d93d4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 13800 images belonging to 46 classes.\n"]}],"source":["test_generator = testing_datagen.flow_from_directory(directory=\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Test\",\n","                                                     target_size=(32,32),color_mode=\"grayscale\",batch_size=13800)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":357,"status":"ok","timestamp":1623647423195,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"80tb0du-Lrud"},"outputs":[],"source":["from tensorflow.python.keras.layers import Input,Dense,Flatten,InputLayer\n","from tensorflow.python.keras.models import Sequential"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1623647424612,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"mMUH4wdsJi62"},"outputs":[],"source":["def build_network():\n","\n","  network = Sequential()\n","  network.add(InputLayer(input_shape=(32,32)))\n","  network.add(Flatten())\n","  network.add(Dense(units=128,activation=\"relu\"))\n","  network.add(Dense(units=46,activation=\"softmax\"))\n","\n","  return network"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5688,"status":"ok","timestamp":1623647433314,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"Uocr8wXqMxG4"},"outputs":[],"source":["network = build_network()"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":362,"status":"ok","timestamp":1623647438121,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"RD8RMc5cM6zO"},"outputs":[],"source":["network.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1609,"status":"error","timestamp":1623647644381,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"},"user_tz":-330},"id":"EChUemUjNUkY","outputId":"8b6760be-afcf-416b-8bc0-3ba5fe4ef0e7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]},{"ename":"UnknownError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-19-a4f941463343\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1957\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-\u003e 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-\u003e 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---\u003e 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train/character_26_yaw/50964.png'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 837, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 963, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train/character_26_yaw/50964.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[sequential/flatten/Shape/_4]]\n  (1) Unknown:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train/character_26_yaw/50964.png'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 837, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 963, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train/character_26_yaw/50964.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_585]\n\nFunction call stack:\ntrain_function -\u003e train_function\n"]}],"source":["network.fit_generator(generator=train_generator,epochs=2,validation_data=validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkt5FuoTmGYJ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN6D5sL9upmaCno5sY5zv1f","mount_file_id":"1BeXFo6ousaI3-Wjn7cLj49CHvWq8PyV6","name":"Multiclass_Classification_Keras.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}