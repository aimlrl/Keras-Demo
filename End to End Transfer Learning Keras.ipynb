{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"End to End Transfer Learning Keras.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18RFrOyVZTtq0xcLkeiryT7IG_-Nz0KLO","authorship_tag":"ABX9TyOTrilPe6lUgVUolD00rcnR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"oxVxl0dsqhWO","executionInfo":{"status":"ok","timestamp":1623900551337,"user_tz":-330,"elapsed":2570,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}}},"source":["from keras.applications import vgg16\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense,Flatten,BatchNormalization\n","from keras.activations import relu\n","from keras.initializers import glorot_uniform\n","from keras.regularizers import l2\n","from keras.optimizers import Adam\n","from keras.models import Sequential"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeFS04w8AD_a","executionInfo":{"status":"ok","timestamp":1623900552728,"user_tz":-330,"elapsed":3,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}}},"source":["data_gen = ImageDataGenerator()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zbjDYcdBH0e","executionInfo":{"status":"ok","timestamp":1623900554366,"user_tz":-330,"elapsed":2,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}}},"source":["import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iv5zMJbAx5_","executionInfo":{"status":"ok","timestamp":1623900637294,"user_tz":-330,"elapsed":81570,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"b243fffd-25e7-4cd9-ac0e-c5ad552c5762"},"source":["training_datagen = data_gen.flow_from_directory(directory=\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train\",\n","                                                target_size=(32,32),color_mode=\"rgb\",\n","                                                classes=os.listdir(\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Train\"),batch_size=50)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found 62560 images belonging to 46 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeJZODDDBiuO","executionInfo":{"status":"ok","timestamp":1623900679147,"user_tz":-330,"elapsed":22745,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"dd16eca1-76cd-429f-d94d-0ae566ace12d"},"source":["cv_datagen = data_gen.flow_from_directory(directory=\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/cv\",\n","                                                target_size=(32,32),color_mode=\"rgb\",\n","                                                classes=os.listdir(\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/cv\"),batch_size=15640)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 15640 images belonging to 46 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQGkV22GCd5O","executionInfo":{"status":"ok","timestamp":1623900722251,"user_tz":-330,"elapsed":20101,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"76042035-3ef2-4408-fe30-4fb968222f8a"},"source":["testing_datagen = data_gen.flow_from_directory(directory=\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Test\",\n","                                                target_size=(32,32),color_mode=\"rgb\",\n","                                                classes=os.listdir(\"/content/drive/MyDrive/DevanagariHandwrittenCharacterDataset/Test\"),batch_size=13800)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found 13800 images belonging to 46 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D9LdGyI4CrZN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623900731549,"user_tz":-330,"elapsed":2027,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"c75e121d-6b9a-4f9b-a94c-38cde83a1a8a"},"source":["conv_base = vgg16.VGG16(include_top=False,input_shape=(32,32,3))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","58900480/58889256 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRk6hSM-DBLM","executionInfo":{"status":"ok","timestamp":1623900745333,"user_tz":-330,"elapsed":413,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"4929ae34-c834-4efe-bd02-e0e7a2d36702"},"source":["conv_base.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X6uCAPNhx4Wh","executionInfo":{"status":"ok","timestamp":1623900747806,"user_tz":-330,"elapsed":342,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}}},"source":["def unfreeze_layers(layer_name):\n","\n","  trainable = False\n","\n","  for layer in conv_base.layers:\n","\n","    if layer.name == layer_name:\n","      trainable = True\n","\n","    if trainable:\n","      layer.trainable = True\n","    else:\n","      layer.trainable = False\n","\n","  return conv_base"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWxlLbTnhYLR","executionInfo":{"status":"ok","timestamp":1623900749329,"user_tz":-330,"elapsed":2,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}}},"source":["def build_network():\n","\n","  network = Sequential()\n","  conv_base = unfreeze_layers(\"block5_conv1\")\n","  network.add(conv_base)\n","  network.add(Flatten())\n","  network.add(Dense(units=512,activation=relu,kernel_initializer=glorot_uniform))\n","  network.add(Dense(units=46,activation=\"softmax\",kernel_initializer=glorot_uniform))\n","\n","  network.compile(optimizer=Adam(learning_rate=0.00001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n","\n","  return network"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQ0YeK3WjnJ4","executionInfo":{"status":"ok","timestamp":1623900750849,"user_tz":-330,"elapsed":2,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}}},"source":["network = build_network()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmdffOGijpvf","executionInfo":{"status":"ok","timestamp":1623900752463,"user_tz":-330,"elapsed":3,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"e411ca38-45ee-4f92-a745-be411a4ccedf"},"source":["network.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               262656    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 46)                23598     \n","=================================================================\n","Total params: 15,000,942\n","Trainable params: 7,365,678\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":955},"id":"7nQHBLayjsTG","executionInfo":{"status":"error","timestamp":1623901556314,"user_tz":-330,"elapsed":792403,"user":{"displayName":"Axis India Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ae171kd--3vHxZ1s3GOc45mMB1L-tiekBKF0pA=s64","userId":"00282416292390226652"}},"outputId":"a101cb94-dd8a-4765-83b8-05c410748f21"},"source":["network.fit_generator(generator=training_datagen,epochs=2,validation_data=cv_datagen,workers=2,use_multiprocessing=True)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2\n"," 124/1252 [=>............................] - ETA: 1:53:57 - loss: 9.2902 - accuracy: 0.0326"],"name":"stdout"},{"output_type":"stream","text":["Process Keras_worker_ForkPoolWorker-1:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 545, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n","    return self._get_batches_of_transformed_samples(index_array)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n","    interpolation=self.interpolation)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n","    img = pil_image.open(io.BytesIO(f.read()))\n","KeyboardInterrupt\n","Process Keras_worker_ForkPoolWorker-2:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 545, in get_index\n","    return _SHARED_SEQUENCES[uid][i]\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n","    return self._get_batches_of_transformed_samples(index_array)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n","    interpolation=self.interpolation)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n","    img = pil_image.open(io.BytesIO(f.read()))\n","KeyboardInterrupt\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-9963ad4bf79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"fIbsp9H1k62Z"},"source":[""],"execution_count":null,"outputs":[]}]}